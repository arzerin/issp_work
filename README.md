#### Computer Vision Research Assistant Work | Yolov8 | Yolov9 | OpenCV | LabelImg 

<a href = "https://www.arzerin.com/">My Website<br><br>


![Arifur Rahman ZERIN github activity graph](https://github-readme-activity-graph.vercel.app/graph?username=arzerin&bg_color=FFFFFF&color=111F68&line=111F68)

<h3>Tasks Accomplished so far?ðŸ’¡</h3>

<h4>make sure you run the below command to install necessary library</h4>
<h5>pip install -r requirements.txt</h5>
<table width="100%">
    <tr>
        <th>Resource Type</th>
        <th width="60%">Title/Information/CodeLink</th>
        <th>Link</th>
    </tr>
    <tr>
        <td>Week 1 <br/><br/> Object (Horse) Detection using Yolov9</td>
        <td  width="60%">This is one of the sample where you can see how I am trying to detect horses after downloading the horse dataset from Roboflow, then finding the horses in the video. I have used Yolov9 here.</td>
        <td>
            Google Colab <a href="https://colab.research.google.com/drive/1OvNOCwxixmEqlUH4Q4O2Q04q6nQtt4Qp?usp=sharing">Online</a> | <a href="week1/yolov9_object(horse)_detection.ipynb">Local</a> <br/><br/>
            <a href="https://universe.roboflow.com/saban-ne0tf/horse-jehyp">Roboflow Dataset of Horse</a>    
        </td>
    </tr>

   <tr>
        <td>Week 1 <br/><br/> Object Detecting in a realtime video using YoloV8, OpenCV</td>
        <td  width="60%">
                This is one of the sample where I am trying to detect falling person in a realtime video using OpenCV & Model that was build using Yolov8. <br/><br/>
                To run the falling detection on a video based on generated model you wil have to run the command: python my.py
        </td>
        <td>
            Google Colab <a href="https://colab.research.google.com/drive/1T0iTyWsMz6o_43sQhm3EvqVykpELRUDJ?usp=sharing"> Online </a> | <a href="week1/yolov8_person_fall_detection.ipynb"> Local </a> <br/><br/>
            <a href="https://universe.roboflow.com/roboflow-universe-projects/fall-detection-ca3o8">Roboflow Dataset of Falling Person </a>    <br/><br/>
            <a href="week1/my.py">python my.py</a><br/><br/>
            <a href="week1/fall.mp4">Falling Video</a>
        </td>
    </tr>
    <tr>
        <td>Week 2 <br/><br/> Model Building from Kaggle | Google Drive</td>
        <td  width="60%">
            I tried to build a model on Shoplifting using Kaggle UCF crime dataset on Shoplifting, I tried to use all the below models to find out which accuracy is good enough. <br/> <br/>
            I have used how to download the data from Google Drive if applicable. <br/> <br/>
            I have used how to download the data from Kaggle also to Google Colab as well to load the dataset directly from there <br/> <br/>
            <table style="border-collapse:collapse; border-spacing:0px; box-sizing:border-box"><tbody><tr><td style="border-width:1pt; border-style:solid; border-color:initial; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><b>No</b></div></td><td style="border-top:1pt solid; border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><b>Model</b></div></td><td style="border-top:1pt solid; border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><b>Accuracy Rate</b></div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">1.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Sequential Model</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.5289999842643738</div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">2.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">ResNet50</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.7480230331420898</div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">3.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">ResNet34</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.9029507040977478</div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">4.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">MobileNet v2</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.8169498443603516</div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">5.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">VGG-19</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.8642555475234985</div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">6.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Vision Transformer</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.6870043873786926</div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">7.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Xception</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:230.6pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">Test accuracy: 0.8287661075592041</div></td></tr></tbody></table>
        </td>
        <td>
            Google Colab <a href="https://colab.research.google.com/drive/1UmGxudtekoUtW5GMG2hoqPmG9KnE2kPz?usp=sharing">Online</a> |  <a href="week2/person_picking_up2.ipynb"> Local </a> <br/><br/>
            <a href="https://www.kaggle.com/datasets/odins0n/ucf-crime-dataset">Kaggle Dataset</a>    
        </td>
    </tr>
    <tr>
        <td>Week 3 <br/><br/> Model Building on YOLOv8, Custom Dataset, Semantic Segmentation</td>
        <td  width="60%">
                Training YOLOv8 on Custom Dataset to use for Semantic Segmentation, tried to download all duck images from Open Database V7, 
                then created label from mask datasets using <a href="week3/masks_to_polygons.py">masks_to_polygons.py</a>, then built the model in google colab <br/><br/>
            Open Data Annotation Software: <br/> <br/>
            <table style="border-collapse:collapse; border-spacing:0px; box-sizing:border-box"><tbody><tr><td style="border-width:1pt; border-style:solid; border-color:initial; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><b>No</b></div></td><td style="border-top:1pt solid; border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><b>Tools</b></div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">1.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><a href="https://www.cvat.ai/">https://www.cvat.ai/</a></div></td></tr><tr><td style="border-right:1pt solid; border-bottom:1pt solid; border-left:1pt solid; padding:0in 5.4pt; vertical-align:top; width:62.75pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)">2.</div></td><td style="border-right:1pt solid; border-bottom:1pt solid; padding:0in 5.4pt; vertical-align:top; width:121.5pt"><div style="margin:0in; font-family:Aptos,Aptos_EmbeddedFont,Aptos_MSFontService,Calibri,Helvetica,sans-serif; font-size:12pt; color:rgb(0,0,0)"><a href="https://github.com/HumanSignal/labelImg">labelImg</a></div></td></tr></tr></tbody></table>
        </td>
        <td>
            Google Colab <a href="https://drive.google.com/file/d/1s6Y-_k_SrVg2h3vu_Y2FpTFsdmka_dNZ/view?usp=sharing">Online</a> | <a href="week3/Download_Data_Semantic_Segmentation_Open_Images_Dataset.ipynb"> Local </a> <br/><br/>
            <a href="https://storage.googleapis.com/openimages/web/index.html">Open Database V7 (duck)</a>    <br/><br/>
        </td>
    </tr>
    <tr>
        <td>Week 4 <br/><br/> Mask Building | Mask R-CNN | Zero Shot | CLIP</td>
        <td  width="60%">
            Worked basic on Mask R-CNN, Zero Shot, CLIP, Grounding Dino, SAM by Facebook.<br/> <br/>
            A hands-on tutorial explaining how to generate a custom Zero-Shot image classifier without training, using a pre-trained CLIP model. Full code included.<br/><br/>
            The CLIP (Contrastive Language-Image Pre-training) model, developed by OpenAI, is a multi-modal vision and language model. It maps images and text descriptions to the same latent space, allowing it to determine whether an image and description match.<br/><br/>
        </td>
        <td>
            <a href="https://colab.research.google.com/drive/1FnQXx6vtefS59mYi_TrEgc9NlvnfLoSR?usp=sharing">Google Colab  Online</a><br/><br/>  <a href="week4/ZeroShot_Clip.ipynb">Google Colab Local</a> <br/><br/>
        </td>
    </tr>
    <tr>
        <td>Week 4 <br/><br/> Grounding Dino | SAM by Facebook</td>
        <td  width="60%">
            Grounding DINO & SAM to Extract Object<br/><br/>
        </td>
        <td>
            <a href="https://colab.research.google.com/drive/1SrpPs9YkNWnt7vZFM0VPUYgTdW3KRyPf?usp=sharing">Google Colab Online</a><br/><br/>  <a href="week4/MyGrounding_DINO_&_SAM_to_Extract_Object.ipynb">Google Colab Local</a> <br/><br/>
        </td>
    </tr>
</table>
